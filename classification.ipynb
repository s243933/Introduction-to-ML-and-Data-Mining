{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "pathname = 'Data/SAheart.data.txt'\n",
    "data = pd.read_csv(pathname, sep=\",\", header=0, index_col='row.names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define dependent and independent variables\n",
    "\n",
    "feature_cols = ['sbp', 'tobacco', 'ldl', 'adiposity', 'typea', 'obesity', 'alcohol', 'age']\n",
    "X = data[feature_cols]  # Training data\n",
    "y = data['chd'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Baseline acc=0.681, mode=0\n",
      "> LR acc=0.745, est=0.699, cfg={'C': 0.1, 'max_iter': 100}\n",
      "> MLP acc=0.766, est=0.696, cfg={'alpha': 0.001, 'learning_rate_init': 0.001} \n",
      "\n",
      "> Baseline acc=0.660, mode=0\n",
      "> LR acc=0.660, est=0.713, cfg={'C': 1.0, 'max_iter': 100}\n",
      "> MLP acc=0.702, est=0.721, cfg={'alpha': 0.01, 'learning_rate_init': 0.001} \n",
      "\n",
      "> Baseline acc=0.587, mode=0\n",
      "> LR acc=0.804, est=0.695, cfg={'C': 1.0, 'max_iter': 100}\n",
      "> MLP acc=0.739, est=0.706, cfg={'alpha': 0.01, 'learning_rate_init': 0.0001} \n",
      "\n",
      "> Baseline acc=0.652, mode=0\n",
      "> LR acc=0.674, est=0.707, cfg={'C': 1.0, 'max_iter': 100}\n",
      "> MLP acc=0.652, est=0.709, cfg={'alpha': 0.0001, 'learning_rate_init': 0.001} \n",
      "\n",
      "> Baseline acc=0.674, mode=0\n",
      "> LR acc=0.630, est=0.716, cfg={'C': 1.0, 'max_iter': 100}\n",
      "> MLP acc=0.696, est=0.731, cfg={'alpha': 0.01, 'learning_rate_init': 0.0001} \n",
      "\n",
      "> Baseline acc=0.543, mode=0\n",
      "> LR acc=0.587, est=0.731, cfg={'C': 0.1, 'max_iter': 100}\n",
      "> MLP acc=0.609, est=0.714, cfg={'alpha': 0.001, 'learning_rate_init': 0.001} \n",
      "\n",
      "> Baseline acc=0.652, mode=0\n",
      "> LR acc=0.739, est=0.699, cfg={'C': 0.1, 'max_iter': 100}\n",
      "> MLP acc=0.674, est=0.690, cfg={'alpha': 0.01, 'learning_rate_init': 0.0001} \n",
      "\n",
      "> Baseline acc=0.674, mode=0\n",
      "> LR acc=0.717, est=0.709, cfg={'C': 0.1, 'max_iter': 100}\n",
      "> MLP acc=0.674, est=0.717, cfg={'alpha': 0.01, 'learning_rate_init': 0.0001} \n",
      "\n",
      "> Baseline acc=0.717, mode=0\n",
      "> LR acc=0.696, est=0.712, cfg={'C': 1.0, 'max_iter': 100}\n",
      "> MLP acc=0.739, est=0.690, cfg={'alpha': 0.01, 'learning_rate_init': 0.0001} \n",
      "\n",
      "> Baseline acc=0.696, mode=0\n",
      "> LR acc=0.717, est=0.700, cfg={'C': 0.01, 'max_iter': 100}\n",
      "> MLP acc=0.652, est=0.680, cfg={'alpha': 0.001, 'learning_rate_init': 0.0001} \n",
      "\n",
      "Baseline Accuracy: 0.654 (0.049)\n",
      "LR Accuracy: 0.697 (0.059)\n",
      "MLP Accuracy: 0.690 (0.046) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Cross-validation\n",
    "\n",
    "K = 10\n",
    "outerCV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# Keep track of scores\n",
    "scores = {'Baseline': [], 'LR': [], 'MLP': []}\n",
    "\n",
    "# Outer CV to find best model\n",
    "for train_idx, test_idx in outerCV.split(X):\n",
    "\n",
    "    # Extract training and test data for current fold\n",
    "    X_train, X_test = X.iloc[train_idx, :], X.iloc[test_idx, :]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Preprocessing\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Inner CV to find best hyperparameters\n",
    "    innerCV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "    \n",
    "    # Define models\n",
    "    Baseline = st.mode(y_train.values)[0] # Baseline\n",
    "    LR = LogisticRegression()   # Logistic regression\n",
    "    MLP = MLPClassifier()   # ANN\n",
    "\n",
    "    # Define search space for hyperparameters\n",
    "    LR_grid = {'C': [0.01, 0.1, 1.0], 'max_iter': [100, 200, 500]}\n",
    "    MLP_grid = {'alpha': [0.0001, 0.001, 0.01], 'learning_rate_init': [0.0001, 0.001, 0.01]} \n",
    "\n",
    "    # GridSearchCV to find best set of hyperparameters\n",
    "    LR_search = model_selection.GridSearchCV(estimator=LR, param_grid=LR_grid, scoring='accuracy', cv=innerCV)\n",
    "    MLP_search = model_selection.GridSearchCV(estimator=MLP, param_grid=MLP_grid, scoring='accuracy', cv=innerCV)\n",
    "    \n",
    "    LR_results = LR_search.fit(X_train_scaled, y_train)\n",
    "    MLP_results = MLP_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get best performing model \n",
    "    LR_best_model = LR_results.best_estimator_\n",
    "    MLP_best_model = MLP_results.best_estimator_\n",
    "\n",
    "    # Make predictions on test set\n",
    "    Baseline_y_preds = np.full(y_test.shape[0], Baseline)\n",
    "    LR_y_preds = LR_best_model.predict(X_test_scaled)\n",
    "    MLP_y_preds = MLP_best_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    Baseline_score = accuracy_score(y_test.values, Baseline_y_preds)\n",
    "    LR_score = accuracy_score(y_test.values, LR_y_preds)\n",
    "    MLP_score = accuracy_score(y_test.values, MLP_y_preds)\n",
    "\n",
    "    # Add score to scores list\n",
    "    scores['Baseline'].append(Baseline_score)\n",
    "    scores['LR'].append(LR_score)\n",
    "    scores['MLP'].append(MLP_score)\n",
    "\n",
    "    # Report progress\n",
    "    print('> Baseline acc=%.3f, mode=%s' % (Baseline_score, Baseline))\n",
    "    print('> LR acc=%.3f, est=%.3f, cfg=%s' % (LR_score, LR_results.best_score_, LR_results.best_params_))\n",
    "    print('> MLP acc=%.3f, est=%.3f, cfg=%s \\n' % (MLP_score, MLP_results.best_score_, MLP_results.best_params_))\n",
    "\n",
    "# Summarize the estimated performance of the model\n",
    "print('Baseline Accuracy: %.3f (%.3f)' % (np.mean(scores['Baseline']), np.std(scores['Baseline'])))\n",
    "print('LR Accuracy: %.3f (%.3f)' % (np.mean(scores['LR']), np.std(scores['LR'])))\n",
    "print('MLP Accuracy: %.3f (%.3f) \\n' % (np.mean(scores['MLP']), np.std(scores['MLP'])))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
